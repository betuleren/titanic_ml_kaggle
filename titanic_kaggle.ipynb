{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Titanic Survival Prediction:**\n",
    "\n",
    "Use machine learning to create a model that predicts which passengers survived the Titanic shipwreck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variables and Their Types:**\n",
    "\n",
    "Survival: Survival -> 0 = No, 1 = Yes\n",
    "\n",
    "Pclass: Ticket class -> 1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "\n",
    "Sex: Sex\n",
    "\n",
    "Age: Age in years\n",
    "\n",
    "SibSp: # of siblings / spouses aboard the Titanic\n",
    "\n",
    "Parch: # of parents / children aboard the Titanic\n",
    "\n",
    "Ticket: Ticket number\n",
    "\n",
    "Fare: Passenger fare\n",
    "\n",
    "Cabin: Cabin number\n",
    "\n",
    "Embarked: Port of Embarkation -> C = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variable Notes:**\n",
    "\n",
    "Pclass: A proxy for socio-economic status (SES)\n",
    "- 1st = Upper\n",
    "- 2nd = Middle\n",
    "- 3rd = Lower\n",
    "\n",
    "Age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "SibSp: The dataset defines family relations in this way...\n",
    "- Sibling = brother, sister, stepbrother, stepsister\n",
    "- Spouse = husband, wife (mistresses and fiancés were ignored)\n",
    "\n",
    "Parch: The dataset defines family relations in this way...\n",
    "- Parent = mother, father\n",
    "- Child = daughter, son, stepdaughter, stepson\n",
    "Some children travelled only with a nanny, therefore parch=0 for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Data Understanding (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Librarires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**numpy:** A fundamental package for scientific computing with Python\n",
    "\n",
    "**pandas:** An open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for Python\n",
    "\n",
    "**matplotlib:** A Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms\n",
    "\n",
    "**seaborn:** A Python data visualization library based on matplotlib; it provides a high-level interface for drawing attractive and informative statistical graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis libraries:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# data visualization libraries:\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# to ignore warnings:\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# to display all columns:\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train and test data with pd.read_csv():\n",
    "\n",
    "train_data = pd.read_csv(\"./data/titanic/train.csv\")\n",
    "test_data = pd.read_csv(\"./data/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy data in order to avoid any change in the original:\n",
    "\n",
    "train = train_data.copy()\n",
    "test = test_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Looking at Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at first few lines with head():\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert some data types into categorical:\n",
    "\n",
    "train.Pclass = pd.Categorical(train.Pclass)\n",
    "train.Name = pd.Categorical(train.Name)\n",
    "train.Sex = pd.Categorical(train.Sex)\n",
    "train.SibSp = pd.Categorical(train.SibSp)\n",
    "train.Parch = pd.Categorical(train.Parch)\n",
    "train.Ticket = pd.Categorical(train.Ticket)\n",
    "train.Cabin = pd.Categorical(train.Cabin)\n",
    "train.Embarked = pd.Categorical(train.Embarked)\n",
    "\n",
    "test.Pclass = pd.Categorical(test.Pclass)\n",
    "test.Name = pd.Categorical(test.Name)\n",
    "test.Sex = pd.Categorical(test.Sex)\n",
    "test.SibSp = pd.Categorical(test.SibSp)\n",
    "test.Parch = pd.Categorical(test.Parch)\n",
    "test.Ticket = pd.Categorical(test.Ticket)\n",
    "test.Cabin = pd.Categorical(test.Cabin)\n",
    "test.Embarked = pd.Categorical(test.Embarked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numerical features:** Age (Continuous), Fare (Continuous), SibSp (Discrete), Parch (Discrete)\n",
    "\n",
    "**Categorical features:** Survived, Sex, Embarked, Pclass\n",
    "\n",
    "**Alphanumeric features:** Ticket, Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structural information about the data:\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments:**\n",
    "\n",
    "There are 891 passengers totally in the training set.\n",
    "\n",
    "The Age feature is missing approximately 19.8%\n",
    "\n",
    "The Cabin feature is missing approximately 77.1%\n",
    "\n",
    "The Embarked feature is missing 0.22%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking of Missing Values and Basic Treatments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structural information about the data:\n",
    "\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Analysis and Visualization of Numeric and Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic summary statistics about the numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes of some categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Pclass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['SibSp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Parch'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Ticket'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Cabin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, barplot is used for categorical variables while histogram, density and boxplot are used for numerical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pclass vs survived:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'Pclass', y = 'Survived', data = train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of Pclass1 survived:\",  train[\"Survived\"][train[\"Pclass\"] == 1].value_counts(normalize=True)[1]*100)\n",
    "print(\"Percentage of Pclass2 survived:\",  train[\"Survived\"][train[\"Pclass\"] == 2].value_counts(normalize=True)[1]*100)\n",
    "print(\"Percentage of Pclass3 survived:\",  train[\"Survived\"][train[\"Pclass\"] == 3].value_counts(normalize=True)[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age vs survived:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the ages into logical categories\n",
    "\n",
    "train[\"Age_new\"] = train[\"Age\"].fillna(-0.5)\n",
    "test[\"Age_new\"] = test[\"Age\"].fillna(-0.5)\n",
    "bins = [-1, 0, 5, 12, 18, 24, 35, 60, np.inf]\n",
    "mylabels = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n",
    "train['AgeGroup'] = pd.cut(train[\"Age_new\"], bins, labels = mylabels)\n",
    "test['AgeGroup'] = pd.cut(test[\"Age_new\"], bins, labels = mylabels)\n",
    "\n",
    "train.AgeGroup = pd.Categorical(train.AgeGroup)\n",
    "test.AgeGroup = pd.Categorical(test.AgeGroup)\n",
    "\n",
    "#draw a bar plot of Age vs. survival\n",
    "sns.barplot(x=\"AgeGroup\", y=\"Survived\", data=train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.pivot_table('Survived', index = 'Sex', columns = 'AgeGroup')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SibSp vs survived:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'SibSp', y = 'Survived', data = train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of SibSp = 0 who survived:\", train[\"Survived\"][train[\"SibSp\"] == 0].value_counts(normalize = True)[1]*100)\n",
    "\n",
    "print(\"Percentage of SibSp = 1 who survived:\", train[\"Survived\"][train[\"SibSp\"] == 1].value_counts(normalize = True)[1]*100)\n",
    "\n",
    "print(\"Percentage of SibSp = 2 who survived:\", train[\"Survived\"][train[\"SibSp\"] == 2].value_counts(normalize = True)[1]*100)\n",
    "\n",
    "print(\"Percentage of SibSp = 3 who survived:\", train[\"Survived\"][train[\"SibSp\"] == 3].value_counts(normalize = True)[1]*100)\n",
    "\n",
    "print(\"Percentage of SibSp = 4 who survived:\", train[\"Survived\"][train[\"SibSp\"] == 4].value_counts(normalize = True)[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parch vs survived:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'Parch', y = 'Survived', data = train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sex vs survived:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'Sex', y = 'Survived', data = train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of female survived:\",  train[\"Survived\"][train[\"Sex\"] == \"female\"].value_counts(normalize=True)[1]*100)\n",
    "print(\"Percentage of male survived:\",  train[\"Survived\"][train[\"Sex\"] == \"male\"].value_counts(normalize=True)[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at age groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'Sex', y = 'Survived', hue = 'AgeGroup', data = train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report based on visual data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* People with higher socioeconomic class had a higher rate of survival.\n",
    "\n",
    "* Babies were more likely to survive than any other age group.\n",
    "\n",
    "* People with more siblings or spouses aboard were less likely to survive. However, contrary to expectations, people with no siblings or spouses were less likely to survive than those with one or two.\n",
    "\n",
    "* People with less than four parents or children aboard were more likely to survive than those with four or more. People traveling alone were less likely to survive than those with 1-3 parents or children.\n",
    "\n",
    "* Females had a much higher chance of survival than males."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Deleting Unnecessary Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**transform sex into numerical data**\n",
    "\n",
    "**drop cabin, ticket, name, age variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can drop the Ticket feature since it is unlikely to have useful information\n",
    "\n",
    "train = train.drop(['Ticket'], axis = 1)\n",
    "test = test.drop(['Ticket'], axis = 1)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age_new was created for creating AgeGroup; unknowns were -0.5. We can delete now.\n",
    "\n",
    "train = train.drop(['Age_new'], axis = 1)\n",
    "test = test.drop(['Age_new'], axis = 1)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fare max datasında bir anormallik var gibi. Bu numerik datayı boxplot ile görselleştir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It looks like there is a problem in Fare max data. Visualize with boxplot.\n",
    "\n",
    "sns.boxplot(x = train['Fare']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = train['Fare'].quantile(0.25)\n",
    "Q3 = train['Fare'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_limit = Q1- 1.5*IQR\n",
    "lower_limit\n",
    "\n",
    "upper_limit = Q3 + 1.5*IQR\n",
    "upper_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observations with Fare data higher than the upper limit:\n",
    "\n",
    "train['Fare'] > (upper_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_tf = train['Fare'] > (upper_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Fare\"][train['Fare'] > (upper_limit)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = train['Fare'][outlier_tf]\n",
    "outliers.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sort_values(\"Fare\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In boxplot, there are too many data higher than upper limit; we can not change all. Just repress the highest value -512- \n",
    "\n",
    "train['Fare'] = train['Fare'].replace(512.3292, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sort_values(\"Fare\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.sort_values(\"Fare\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Fare'] = test['Fare'].replace(512.3292, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.sort_values(\"Fare\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Missing Value Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age'i doldurmak için title'lar kullanılacak. Title'ları cogaltmak için combine train and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use titles to fill missing Age value. Combine train and test data:\n",
    "\n",
    "combine = [train, test]\n",
    "combine = pd.concat(combine, ignore_index = True)\n",
    "combine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values in combine:\n",
    "\n",
    "combine.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Title variable in combine; take titles from Name data:\n",
    "\n",
    "combine[\"Title\"] = combine[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "combine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combine içinden title, age ve survived değişkenlerini seç, groupby ile title'lara göre grupla, aggregate ile farklı değişkenlere farklı fonksiyonlar uygula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine[[\"Title\",\"Age\",\"Survived\"]].groupby(\"Title\").aggregate({\"Age\":[\"count\",\"mean\",\"median\",\"std\"], \n",
    "                                                                \"Survived\": \"mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine[(combine[\"Age\"].isnull()) & (combine[\"Title\"] == \"Master\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine[[\"Title\",\"Age\",\"Survived\"]].groupby(\"Title\").agg({\"Age\":[\"count\",\"mean\",\"median\",\"std\", lambda x: x.isnull().sum()], \n",
    "                                                                \"Survived\": \"mean\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** You can use agg or apply for isnull but agg can use different functions for different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine[[\"Title\",\"Age\"]].groupby('Title').agg({'Age': lambda x: x.isnull().sum()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine[[\"Title\",\"Age\"]].groupby('Title').apply(lambda x: x.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine[\"Age\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each missing value in Age according to titles will be filled with its own average value:\n",
    "\n",
    "combine[\"Age\"] = combine[[\"Title\",\"Age\"]].groupby(\"Title\").transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "combine.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine[\"Age\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 891 rows according to PassengerId were in the train data while others were in the test data\n",
    "\n",
    "train[\"Age\"] = pd.DataFrame(combine[\"Age\"][0:891])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Age\"] = pd.DataFrame(combine[\"Age\"][891:len(combine)]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Age\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Age\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign again to AgeGroup:\n",
    "\n",
    "bins = [0, 5, 12, 18, 24, 35, 60, np.inf]\n",
    "mylabels = ['Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n",
    "train['AgeGroup'] = pd.cut(train[\"Age\"], bins, labels = mylabels)\n",
    "test['AgeGroup'] = pd.cut(test[\"Age\"], bins, labels = mylabels)\n",
    "\n",
    "#train.AgeGroup = pd.Categorical(train.AgeGroup)\n",
    "#test.AgeGroup = pd.Categorical(test.AgeGroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Age\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Age\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"AgeGroup\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"AgeGroup\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NA with the most frequent value:\n",
    "\n",
    "train = train.fillna({\"Embarked\": \"S\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test[\"Fare\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[[\"Pclass\",\"Fare\"]].groupby(\"Pclass\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Fare\"] = test[\"Fare\"].fillna(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Fare\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CabinBool variable which states if someone has a Cabin data or not:\n",
    "\n",
    "train[\"CabinBool\"] = (train[\"Cabin\"].notnull().astype('int'))\n",
    "test[\"CabinBool\"] = (test[\"Cabin\"].notnull().astype('int'))\n",
    "\n",
    "train = train.drop(['Cabin'], axis = 1)\n",
    "test = test.drop(['Cabin'], axis = 1)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Variable Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map each Embarked value to a numerical value:\n",
    "\n",
    "embarked_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n",
    "\n",
    "train['Embarked'] = train['Embarked'].map(embarked_mapping)\n",
    "test['Embarked'] = test['Embarked'].map(embarked_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Sex values into 1-0:\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "lbe = preprocessing.LabelEncoder()\n",
    "train[\"Sex\"] = lbe.fit_transform(train[\"Sex\"])\n",
    "test[\"Sex\"] = lbe.fit_transform(test[\"Sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name - Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Title\"] = train[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "test[\"Title\"] = test[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Title'] = train['Title'].replace(['Lady', 'Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\n",
    "train['Title'] = train['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\n",
    "train['Title'] = train['Title'].replace('Mlle', 'Miss')\n",
    "train['Title'] = train['Title'].replace('Ms', 'Miss')\n",
    "train['Title'] = train['Title'].replace('Mme', 'Mrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Title'] = test['Title'].replace(['Lady', 'Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\n",
    "test['Title'] = test['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\n",
    "test['Title'] = test['Title'].replace('Mlle', 'Miss')\n",
    "test['Title'] = test['Title'].replace('Ms', 'Miss')\n",
    "test['Title'] = test['Title'].replace('Mme', 'Mrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[[\"Title\",\"PassengerId\"]].groupby(\"Title\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map each of the title groups to a numerical value\n",
    "\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royal\": 5, \"Rare\": 6}\n",
    "\n",
    "train['Title'] = train['Title'].map(title_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Title'] = test['Title'].map(title_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['Name'], axis = 1)\n",
    "test = test.drop(['Name'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AgeGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map each Age value to a numerical value:\n",
    "\n",
    "age_mapping = {'Baby': 1, 'Child': 2, 'Teenager': 3, 'Student': 4, 'Young Adult': 5, 'Adult': 6, 'Senior': 7}\n",
    "train['AgeGroup'] = train['AgeGroup'].map(age_mapping)\n",
    "test['AgeGroup'] = test['AgeGroup'].map(age_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the Age feature for now, might change:\n",
    "\n",
    "train = train.drop(['Age'], axis = 1)\n",
    "test = test.drop(['Age'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Fare values into groups of numerical values:\n",
    "\n",
    "train['FareBand'] = pd.qcut(train['Fare'], 4, labels = [1, 2, 3, 4])\n",
    "test['FareBand'] = pd.qcut(test['Fare'], 4, labels = [1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Fare values:\n",
    "\n",
    "train = train.drop(['Fare'], axis = 1)\n",
    "test = test.drop(['Fare'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Family Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"FamilySize\"] = train_data[\"SibSp\"] + train_data[\"Parch\"] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"FamilySize\"] = test_data[\"SibSp\"] + test_data[\"Parch\"] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new feature of family size:\n",
    "\n",
    "train['Single'] = train['FamilySize'].map(lambda s: 1 if s == 1 else 0)\n",
    "train['SmallFam'] = train['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\n",
    "train['MedFam'] = train['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\n",
    "train['LargeFam'] = train['FamilySize'].map(lambda s: 1 if s >= 5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new feature of family size:\n",
    "\n",
    "test['Single'] = test['FamilySize'].map(lambda s: 1 if s == 1 else 0)\n",
    "test['SmallFam'] = test['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\n",
    "test['MedFam'] = test['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\n",
    "test['LargeFam'] = test['FamilySize'].map(lambda s: 1 if s >= 5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embarked & Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Title and Embarked into indicator values:\n",
    "\n",
    "train = pd.get_dummies(train, columns = [\"Title\"])\n",
    "train = pd.get_dummies(train, columns = [\"Embarked\"], prefix=\"Em\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.get_dummies(test, columns = [\"Title\"])\n",
    "test = pd.get_dummies(test, columns = [\"Embarked\"], prefix=\"Em\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create categorical values for Pclass:\n",
    "\n",
    "train[\"Pclass\"] = train[\"Pclass\"].astype(\"category\")\n",
    "train = pd.get_dummies(train, columns = [\"Pclass\"],prefix=\"Pc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Pclass\"] = test[\"Pclass\"].astype(\"category\")\n",
    "test = pd.get_dummies(test, columns = [\"Pclass\"],prefix=\"Pc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[[\"Ticket\",\"PassengerId\"]].groupby(\"Ticket\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TicketPre = []\n",
    "\n",
    "for i in list(train_data.Ticket):\n",
    "    if not i.isdigit() :\n",
    "        TicketPre.append(i.replace(\".\",\"\").replace(\"/\",\"\").strip().split(' ')[0]) #Take prefix\n",
    "    else:\n",
    "        TicketPre.append(\"X\")\n",
    "        \n",
    "train[\"TicketPre\"] = TicketPre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"TicketPre\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[[\"TicketPre\",\"Survived\"]].groupby(\"TicketPre\").agg({\"TicketPre\": \"count\", \"Survived\": \"mean\"}).sort_values(\"Survived\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TicketPre = []\n",
    "for i in list(test_data.Ticket):\n",
    "    if not i.isdigit() :\n",
    "        TicketPre.append(i.replace(\".\",\"\").replace(\"/\",\"\").strip().split(' ')[0]) #Take prefix\n",
    "    else:\n",
    "        TicketPre.append(\"X\")\n",
    "        \n",
    "test[\"TicketPre\"] = TicketPre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"TicketPre\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns = [\"TicketPre\"], prefix=\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.get_dummies(test, columns = [\"TicketPre\"], prefix=\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check and compare the columns in the train and the test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(train.columns) == set(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns in both data:\n",
    "\n",
    "train.columns.intersection(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns in train but not in test:\n",
    "\n",
    "train.columns.difference(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"T_AS\"] = 0\n",
    "test[\"T_CASOTON\"] = 0\n",
    "test[\"T_Fa\"] = 0\n",
    "test[\"T_LINE\"] = 0\n",
    "test[\"T_PPP\"] = 0\n",
    "test[\"T_SCOW\"] = 0\n",
    "test[\"T_SOP\"] = 0\n",
    "test[\"T_SP\"] = 0\n",
    "test[\"T_SWPP\"] = 0\n",
    "test[\"Title_5\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns in test but not in train:\n",
    "\n",
    "test.columns.difference(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"T_A\"] = 0\n",
    "train[\"T_AQ3\"] = 0\n",
    "train[\"T_AQ4\"] = 0\n",
    "train[\"T_LP\"] = 0\n",
    "train[\"T_SCA3\"] = 0\n",
    "train[\"T_STONOQ\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Modeling, Evaluation and Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "predictors = train.drop(['Survived', 'PassengerId'], axis=1)\n",
    "target = train[\"Survived\"]\n",
    "x_train, x_val, y_train, y_val = train_test_split(predictors, target, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "88dded62-0c57-499c-9588-4f74816b15b2",
    "_uuid": "fd9a6356a5a629243a771e47e1e64f2f579f96ef"
   },
   "source": [
    "## Testing with Different Models\n",
    "I will be testing the train data by using following models:\n",
    "\n",
    "* Gaussian Naive Bayes\n",
    "* Logistic Regression\n",
    "* Support Vector Machines\n",
    "* Perceptron\n",
    "* Decision Tree Classifier\n",
    "* Random Forest Classifier\n",
    "* KNN or k-Nearest Neighbors\n",
    "* Stochastic Gradient Descent\n",
    "* Gradient Boosting Classifier\n",
    "\n",
    "For each model, we set the model, fit it with 80% of our training data, predict for 20% of the training data and check the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model1: Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "09621103-fb65-4a5a-a3ed-11ca8220532e",
    "_uuid": "aef1d16c06bbf392b076aa5793899f6f4d0a1bfd"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(x_train, y_train)\n",
    "y_pred = gaussian.predict(x_val)\n",
    "acc_gaussian = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(acc_gaussian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model2: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bcfef788-53b1-47b3-9415-89b551840bd7",
    "_uuid": "7d3745861c316a25489e7c03c7de706fa00f0303"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)\n",
    "y_pred = logreg.predict(x_val)\n",
    "acc_logreg = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(acc_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model3: Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "56dac308-6168-4b68-b6b9-41687e187441",
    "_uuid": "3e665ac1a91527d72a54f743fb00f2a44b54e53b"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(x_train, y_train)\n",
    "y_pred = svc.predict(x_val)\n",
    "acc_svc = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(acc_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model4: Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d67c8296-38d6-4887-a314-6858b43a985e",
    "_uuid": "f6b0e28b01c274883bb8eda2e11972bed895ce86"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(x_train, y_train)\n",
    "y_pred = linear_svc.predict(x_val)\n",
    "acc_linear_svc = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(acc_linear_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model5: Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "649c3e1b-0212-4102-b106-c365eb1aca76",
    "_uuid": "5093a9c5c2856bb4a3adb4c6d22f7bbad20b9f6b"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(x_train, y_train)\n",
    "y_pred = perceptron.predict(x_val)\n",
    "acc_perceptron = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(acc_perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model6: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6fcd6c44-6611-44e5-a198-005f97891994",
    "_uuid": "e31d8c0a7ad10221e77309cd80f33439ccfdb746"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decisiontree = DecisionTreeClassifier()\n",
    "decisiontree.fit(x_train, y_train)\n",
    "y_pred = decisiontree.predict(x_val)\n",
    "acc_decisiontree = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(acc_decisiontree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model7: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6a91127f-dc04-4b1d-9072-fa155869c0ab",
    "_uuid": "f5dd894aaf3ba31c3c4b151bc83e1fd6298312b9"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randomforest = RandomForestClassifier()\n",
    "randomforest.fit(x_train, y_train)\n",
    "y_pred = randomforest.predict(x_val)\n",
    "acc_randomforest = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(acc_randomforest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model8: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cf3742ce-e4ba-4b97-80fe-f0dbc1255ca4",
    "_uuid": "dd4b169685df45ef10647fe48f9309cf01bdefc1"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_val)\n",
    "acc_knn = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(acc_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {\"n_neighbors\": np.arange(1,50)}\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv = GridSearchCV(knn, knn_params, cv=10)\n",
    "knn_cv.fit(x_train, y_train)\n",
    "print(\"The best score:\" + str(knn_cv.best_score_))\n",
    "print(\"The best parameters: \" + str(knn_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(3)\n",
    "knn_tuned = knn.fit(x_train, y_train)\n",
    "y_pred = knn_tuned.predict(x_val)\n",
    "acc_knn = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(acc_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model9: Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "39e44b70-bb5f-4f8b-9f54-cce63133f026",
    "_uuid": "18f62721f191cada9a368c22c76f30bbc97255e0"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(x_train, y_train)\n",
    "y_pred = sgd.predict(x_val)\n",
    "acc_sgd = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(acc_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model10: Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5716dd13-ca67-4651-9e58-02a1fb59189a",
    "_uuid": "5c1099ee0d5ad5bc1e4f96ee825c36afe2611fbd"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbk = GradientBoostingClassifier()\n",
    "gbk.fit(x_train, y_train)\n",
    "y_pred = gbk.predict(x_val)\n",
    "acc_gbk = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(acc_gbk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "        'n_estimators': [100, 500, 1000, 2000],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5,6],\n",
    "        'learning_rate': [0.1,0.01,0.02,0.05],\n",
    "        \"min_samples_split\": [2,5,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = GradientBoostingClassifier()\n",
    "\n",
    "xgb_cv_model = GridSearchCV(xgb, xgb_params, cv = 10, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cv_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = GradientBoostingClassifier(learning_rate = 0.01, \n",
    "                    max_depth = 5,\n",
    "                    min_samples_split = 5,\n",
    "                    n_estimators = 100,\n",
    "                    subsample = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_tuned =  xgb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_tuned.predict(x_val)\n",
    "acc_gbk = round(accuracy_score(y_pred, y_val) * 100, 2)\n",
    "print(acc_gbk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b342b59d-501b-4711-8620-206ff34659ab",
    "_uuid": "21c87e41c2d99d5b4e2adee35247a95f23937447"
   },
   "source": [
    "## Choosing the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "351eede6-d162-4420-a2f4-8637f40c4a2d",
    "_uuid": "230e7f53405181667f229b15700329f372725c10"
   },
   "outputs": [],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes', 'Perceptron', 'Linear SVC', \n",
    "              'Decision Tree', 'Stochastic Gradient Descent', 'Gradient Boosting Classifier'],\n",
    "    'Score': [acc_svc, acc_knn, acc_logreg, \n",
    "              acc_randomforest, acc_gaussian, acc_perceptron,acc_linear_svc, acc_decisiontree,\n",
    "              acc_sgd, acc_gbk]})\n",
    "models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set ids as PassengerId and predict survival \n",
    "ids = test['PassengerId']\n",
    "predictions = xgb_tuned.predict(test.drop('PassengerId', axis=1))\n",
    "\n",
    "#set the output as a dataframe and convert to csv file named submission.csv\n",
    "output = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://numpy.org/\n",
    "\n",
    "https://pandas.pydata.org/\n",
    "\n",
    "https://matplotlib.org/#\n",
    "\n",
    "http://seaborn.pydata.org/\n",
    "\n",
    "https://www.kaggle.com/nadintamer/titanic-survival-predictions-beginner\n",
    "\n",
    "https://www.kaggle.com/startupsci/titanic-data-science-solutions\n",
    "\n",
    "https://www.kaggle.com/jeffd23/scikit-learn-ml-from-start-to-finish?scriptVersionId=320209"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
